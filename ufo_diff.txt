
# system 和 监听不能同步进行，所以需要需要开两个进程。

# fork中的管道

# 改为poll监听管道的fd。然后成为读写事件了？

# 改为poll 读写一行行的方式的读写？ 是的。

#服务状态，

#获取存储状态，

#获取配置时间服务状态。

# 获取IP，获取主机名，主机UUID，获取网卡，网络信息,网卡连接等状态 。

# 解析ifconfig ethtool，采用正则解析。分段，等等, 多添加几块网卡。

# 文件读取1024大小数据

# centos6 上安装mongodb

## ？？ 创建mongodb

## 修改mongodb 数据库
## !! 后端开发整理？还是边开发就好了？还是需要整理的。
## !! 用户模型，登录系统等等。token，类型，增加新的API

## 研究MySQL-python

## CREATE DATABASE cloudweb;

## email 作为uuid的唯一区别，不设置uuid字段
## name 作为在文件系统上的索引了。是的。 但是还是要增加引用？是的。
## create table user(
## id bigint NOT NULL AUTO_INCREMENT,
## name varchar(255) NOT NULL,
## type int ,
## email varchar(255) NOT NULL,
## password text,
## state char(8),
## );

## drop table person;

## alter table user add id int NOT NULL AUTO_INCREMENT; -> alter table user add id int NOT NULL PRIMARY KEY AUTO_INCREMENT;

## alter table user modify name NOT NULL; -> alter table user modify name varchar(255) NOT NULL;
## alter table user modify email NOT NULL; -> alter table user modify email varchar(255) NOT NULL;

## 增加用户表user，文件表stobj

## user foreign key stobj

## 外键及其查询太过于复杂，因此暂时不使用外键了

## 增加parent，方便直接查询。查询其子目录了。

## create table stobj( id bigint NOT NULL PRIMARY KEY AUTO_INCREMENT, path varchar(65535) NOT NULL, parent varchar(65535),type char(16),parent_id bigint, state char(16)); -> path text,parent text;

## alter table stobj drop column parent_id;

## alter table stobj add path text NOT NULL;
## alter table stobj add parent text  NULL;

## parent 和parent_id 是等价的，无非就是把path换成path，多增加一次查询。

## state 只对文件有效，禁用和启用。删除，是外键级联

## 需要修改my.cn 增加 default-storage-engine=INNODB

## create table stobj( id bigint NOT NULL PRIMARY KEY AUTO_INCREMENT,path  text NOT NULL,type char(16),parent_id bigint,state char(16),CONSTRAINT xiaodi_ibfk_1 FOREIGN KEY (parent_id) REFERENCES stobj (id) on delete cascade  on update cascade  );

## create table stobj( id bigint NOT NULL PRIMARY KEY AUTO_INCREMENT,path  text NOT NULL,type char(16),parent_id bigint,state char(16),CONSTRAINT xiaodi_ibfk_1 FOREIGN KEY (parent_id) REFERENCES stobj (id) on delete cascade on update cascade  );

## create table stobj( id bigint NOT NULL PRIMARY KEY AUTO_INCREMENT,path  varchar(255) NOT NULL,type char(16),parent_id bigint,state char(16),CONSTRAINT xiaodi_ibfk_1 FOREIGN KEY (parent_id) REFERENCES stobj (id) on delete cascade on update cascade  );

## 无法解决移动目录的问题。无法采用全路径了？直接修改为和文件系统相同的了？关键是查询会费劲了。不能直接ls了。是的。

## 采用相对部分路径，解决移动目录的问题。采用级联删除，解决目录删除的问题。如果复制目录？ 没新增加一个目录，则对整体的文件，进行复制了。自己重写复制的函数了。是的。 修改复制目录的接口，复制每个文件，增加复制时的数据库操作了。

## 复制完毕后，增加数据库操作
#
## insert into stobj(path,type,state) values('a','dir','enable');insert into stobj(path,type,parent_id,state) values('a','dir',1,'enable');

## 查询时parent_id 不为null，因此，增加type为account 。其他则是path 以及id了。

## delete from stobj where id=1;

## alter table stobj add constraint parent_check foreign key(parent_id) references stobj(id) on delete cascade on update cascade;

## CREATE TABLE `components` (  
##    `id` int(10) unsigned NOT NULL auto_increment,  
##    `typeId` int(10) unsigned NOT NULL,  
##    `moreInfo` VARCHAR(32),   
##    -- etc  
##    PRIMARY KEY (`id`),  
##    KEY `type` (`typeId`)  
##    CONSTRAINT `myForeignKey` FOREIGN KEY (`typeId`)  
##      REFERENCES `types` (`id`) ON DELETE CASCADE ON UPDATE CASCADE  
##)  



## 研究缓存结构。文件缓存结构。 绕过memcache，直接编写一个cache服务端端。包括插入，浏览，删除，等等。可以直接绕过数据库了？是的。创建文件，浏览，删除文件。并且会操作数据库。是的。等于一个用户手动操作，需要处理三个了。是的。是否需要经过数据库？经过，就当技术储备了。

增加查询web服务。list操作，在数据库本地执行。判断list。

## 编写脚本，处理文件系统。把文件系统的关系，导入到数据库中。

## 导入用户关系。是的。更具层数和属性，决定type了。

## 生成数据库表的数据。

## 增加数据库接口

## 插入account，插入container，插入dir，插入file

## 增加pymongo的数据库的转化？性能数据？是的。

## 此处数据库，parent和child的目录关系，必须采用级联。以及onupdate的级联？如何？外键的修改？如何？需要嵌套的内容是比较多的。

## GRANT ALL PRIVILEGES ON *.* TO 'root'@'%’ IDENTIFIED BY '111111' WITH GRANT OPTION;

关于用户模块？和文件系统模块？几个核心模块，现在自己是完全没有概念了。也不知道那个模块，自己该做什么了。是的。之前记得需要写一个服务的。两边进行retful调用，前端和后端，都是restful来了，现在，怎么直接就访问数据库就好了？貌似是的。

那时候是因为直接访问文件系统了？现在呢？应该不是了。应该还是服务了。访问数据库的连接，不能利用api的了。否则的没调用一次，绝对受不了。必须是经常性的才行了。

## 编写cloudfs的插件。是的。

cloudfs 的中间件

cloudfs bug解决 ？？

url重新梳理？ 文件系统重新导向为数据库。参数重新规划。

重新来吧？是的。 中科院的数据，如何处理？是的。 用户文件系统上的内容不用动。

涉及文件系统的

涉及用户系统的

用户注册，等等。 文件修改。这几个应该是核心的功能了。

先满足基本的数据需求了。 不对cloudfs进行修改。先修改cloudweb的数据库。

默认创建admin 用户

## 编写user 操作接口。create，delete，update
## 编写stobj 操作接口。
## account 创建，删除，list
## container 创建，删除，list
## dir 创建，删除，list
## file创建，list

## 在cloudfs中添加cloudweb，然后逐渐对于cloudfs的内容进行删除。完成cloudweb目录的创建了。是的。

## 制作失败，没有包含cloudweb，没有创建__init__.py ，同时移除psutil等源码包，移除C语言文件等非.py 文件

## 制作失败，删除build/lib 内部的相关文件

## 主名为cloudweb，副为ui，统一在cloudweb下面。

## web 包含cloudweb，并替换ufo的位置了。

## cloudweb 将来恐怕还是需要继续进行拆分。满足swift的插件。以及总的方式了。

## 修改相关文件为cloudweb形式的。

## 制作cloudweb rpm包，然后cloudfs调用，中间件，才能搞了。是的。

## 研究cloudfs最小包。进行一个精简。是的。对于其的SOURCE和SPCE。

## 编译包

## 调整cloudweb的形式？调整用户注册步骤。采用account put的操作。而不是直接的put container的过程中产生了。

## AUTH_zhu__feng00000com,调整account和数据库的形式了？,有必要么？貌似没有啊

## 深层目录创建，则在数据库中深层目录创建。

## 解决segments中乱码的错误。因为使用CREATE 参数，则无错。但是使用PUT 上传文件失败 .被quote了两次。应该是在cnlib的过程中了。 需要有一个明确的层次，且这个层次只应该被调用一次,因为函数调用，被重复了两次了。

## 移动目录的时候，或者copy 或许有问题，是的。 先删除，再插入，使得子文件/目录被丢弃了。只能修改.获取id，new_parent_id ,修改parent_id 和 path

## 关于中层目录的拷贝，就是遍历。没遍历的内容，都会重新的插入一遍了。是的。需要用队列？bfs算法。吧。是的。

## 完成copy_object 函数。

## account去重。是的。数据库去重检测。直接返回错误，即可。或者使用数据库检测替换掉文件系统了。是的。对于cloudfs进行大的修改了？

MySql connection 和 HTTPConnection 都是要作为资源的了。包括抓取到的结果，也是会作为对象进行保存了，防止被过度使用了。

对于测试用例，要求直接进行改造了。是的。 完成面向对象的操作。是的。

整合测试用例。改造level等相关操作函数。 改造为object，account，container对象等。并可以打印函数信息。打印接口信息。

想要再增加一层request层，并把相关测数据库操作加入到相关的层次中去来。

削减开发成本吧。还是。先把基本的API完成。是的。 整合所有的测试资源，削减相关的开发成本。是的。 打印函数的相关信息？是的。

现在的问题出来了。对于现实的不满，而不是利用不满的现实了。比如说metadata等，如果利用这些扯淡的现实了，那么API接口早就写出来了。对于现实不满，因此逆袭改造了。改造废墟了，而不是从废墟中诞生了。从testcase中写，真是扯淡。哎。

竟然一直在花时间对于原有的内容进行修修补补，而不是利用原有的内容了。在原有的内容诞生出新的内容才是王道啊。开拓新世界，而不是局限于旧有的世界了。这个应该就是冯同学的理念吧。

如何才能不改造旧世界？而不是让旧世界，孵化出新世界？比如，再现有的基础上写出来新的功能了。而不是按照我们的意愿，对于旧世界进行改造了。花在旧世界上的时间，整改旧有的世界，不如把时间花在孕育孵化新的世界中了。是的。实现了快速狂飙。而不是扩大胜利果实了。这tm的才是险路了。而不是我们想要的内容了。把修改雾霾了。是的。

所以说，旧世界不要研究。直接诞生就可以了。但是写程序不同，需要旧空间内进行重新规划的。而这种旧世界诞生新世界的过程中，是没有规划的。所以还是需要规划，是的。

因此，我是花费大量的时间，在规划旧世界，研究旧世界了。而没有对其的结果进行直接的利用了。是的。在旧世界的框架内研究，或者说是旧世界内容的视角了。但是条件作为诞生和孵化，是进入到新世界中的。这个就是内向和外向的区别了？

花费大量的时间在研究旧有的世界了，而没有快速的开拓新的世界了。是的。对于旧有世界的不满，可以通过函数的封装，来实现了。是的。所以说，快速的向新世界跃进才是关键了？而不是要对于旧有世界的不满了。但是现在我们现在确实没有好好的对于旧有的世界，对于项目的整体作出规划。还是需要进行好好的规划下。

因此，对于原有的函数，不进行否定，而是重新写一套接口，增加调试信息。是的。

如果反映过慢，则可研究，如何用数据库进行优化了。

对于旧世界，对于整体的项目进行规划，对于新世界进行你个促进了。在其作为的条件上。诞生孕育和孵化了。因为条件存在满足了，所以有些情况就可能了。

用户数据校验。

编写文件检索函数。先快速的把系统需要的API完成再说吧。不要去想这个想那个了。


===============================================================================================

增加ApiEvent 类。HTTPConnection,MySql 都是其的资源。以及token亦是资源。以及userinfo。

对于旧有函数的封装？那么我们现在的进步又该如何进行规划？那就是让其不断的对旧世界进行扩张了？可以这样理解么？层层实现对于旧世界的扩张了？然后达到彼岸了？
增加新的插件？用户插件？和quota插件？用户注册插件？ 增加quota表。如果条件成熟，那么我们就把quota以及metadata等信息，该转移到数据库中了。是的。

因为对于新世界的扩张有抵触感了？因为在一直收拾旧世界了？应该是。差不多。看来还是编程能够改造自己了。自己扩张新世界。比看书好的多。是的。

因此，实现的思路应该是个样子的。迭代式开发。第一阶段，对于项目作为旧世界的规划。规划完后，就是快速的实现了。此时是新世界的诞生。要求快速的实现了新世界了。待新世界实现后，再重新对于旧有的世界进行规划了。是的。

所以，先规划出新世界，然后对于新世界的快速的实现。比如提出的新的点子。然后实现后，再对于原有的代码，进行一个重新的规划。不断的规划，不断的重构了。是的。

那么我们对于新世界的态度如何？制定新的世界，快速的达到了？以新世界为中心？寻找着陆点，然后快速的达到了？而不是以前以某个为根基了？逐渐的发展了？现在应该不是了。比如说用户操作记录。那么就是用户操作记录作为中心，单独的从周围进行发展了？而不是把自己放进更大的框架来处理了？

比如说之前的方式，访问文件系统，可以快速的达到了？但是要加上数据库，因为IO交互的问题了？所以要重定向到数据库上了。

如果能直线，那就直线，先快速的达到目的。达到新世界，然后对于旧世界再进行重新规划，进行重构了。那么之前的编程思路是什么样子的？是的。

再比如说，关于quota和用户操作记录的写作。完全就是直线式的了，而没有任何的其他式的架构和思想了。是的。不需要什么平台了。不需要什么思想了。是的。就是干。因为之前要按照意志来进行修改了？按照某些规律？按照某些的思想了？但是现在就是非常的简单了？不需要体现出来任何的内容。就是简单直接了？在旧式世界内，直接进行条件诞生了。是的。在现实和目的直接，划出了最短的直线了。以前写程序，是怎么写的？比如说是需要提炼出什么思想了。达到了什么境界了。现在就是简单直接了。是的。基于实力，基于现实的野心更大了。利用现实的崛起，渐渐的向目标靠拢了。现在，直接从目标为起点了，向周围划最近的线了。以前是现实的崛起，达到了目标。现在是目标直接向现实靠拢了。是的。

以前是用思想来主导工作中的目标了。现在则不是了，直接是目标和现实间划线了。

简单直接，才是最为原始的了。

两个主导，发生了变化，以前是自己为中心来主导。现在直接是目的为中心来主导了。是的。现在写程序的思路。和之前写程序的思路的不同。就是在目的和现实之间进行优化了。但是以前不是了。这个应该是受玩游戏的影响了。是的。优化中间的空洞地带了？

但是现在的很多的事情，是自己无法理解了。但是以前就容易理解了。比如说频繁的访问文件系统等。现在看起来就是理所应当的。但是之前的思路是，访问这个会造成文件系统卡死。所以还是访问内存吧。所以以前还是唯物来主导的？现在就是目的，快速的着陆来主导的？而不是唯物的主导的？唯物主导，就是旧世界的主导了。而唯心主导，就是新世界的主导了？然后重新回忆下，之前的抽象是怎么回事，就是对于旧世界的重新规划了？按照更为合理的方式了？

现在是通过新世界对于旧世界的拉动了。以前呢？是对于旧世界的重新规划了？

还是编程带给自己的冲击大，比读书强多了。编程中，很多的新大陆被发现了，很多激烈的思想在交锋。但是读书，则没有了。所以，事情还是要干，在干的过程中，会体验出来更多了。

编程中，必须要实现新世界对于旧世界的拉动了。以前呢？是以旧世界为目的的。或者说，站在旧有的世界，向着新世界的出发了。集中所有旧世界的力量，然后达到了目的了。改造旧世界的方式了，改造条件的方式。现在呢？是新的世界，直接向条件靠拢了？应该是吧。感觉挺扯淡的。

读书，以旧世界的本质为目的了。是的。所以对于旧世界的本质认识的还是非常的深刻的。 因为自己一直爬在地上的？而不是目标对于现实的指导了？

学习，学习，是目的向现实靠拢了。是的。以目的向现实靠拢，而不是让现实或者旧世界向现实的发展了。

所以今天的写代码，比如说修改整合测试代码，就是通过对于原有代码的修改，逐渐的进步，发展，进步和发展唯物的方式，逐渐的接近目标了。所以比较扎实了。是的。完全是跟从现实的了。是的。但是，今天的方式，不理会，或者说屏蔽掉底层，使得自己不把大把的时间浪费在旧世界上了。而是直接让目的达到了旧世界了？是的。但是呢？对于后续的稳定性的分析，该如何理解？因为旧世界的形而上，还是非常的重要的了？旧世界的形而上。添加了中间层次，还是比较牛逼的了。是的。

失去了改造旧有世界的唯物了。是的。

关于规划，和按规律的发展？如何？那么当初的规划，是如何的？战略规划的思路了？规律的发展了？现在呢？应该不是了。

一个是新世界对于旧世界的吸引了。另一个则是旧世界的发展了？模仿和抄袭？比如说百度云的链接？或者说SSD的迁移等等？貌似是啊。当初的脑洞是怎么开的？扯淡了。思维改革和思维改革，改的真是扯淡了。

以前对于新的内容，是作为攻击者，研究的是旧世界了。现在呢？规划出新世界了，然后如何向旧世界靠拢，或者说拉拢旧世界，而不是让旧世界的发展，来达到了新世界了。以前，就是通过旧世界的发展，来达到了新世界的。而不是新世界对于旧有世界的拉拢了。

在旧世界向新世界的逼近中，不断的调整自身的姿势了。追求更为光明，更为广阔的天空了？因此这个就是SSD功能和MD5文件系统诞生的基础了。通过不断的优化自身了。但是另一种方式，就是新世界对于旧世界的拉拢了，直接直线式的拉拢了？这个貌似是比较吊了。然后旧世界就放弃了自身的发展了？貌似是的。

关于旧世界的力量，有追求的旧世界。现在只是新世界调戏旧世界而已了。没啥意思了。之前的思路是怎么想的？现在还能去想么？貌似是不行了。是的。

以前在规划的过程中，是在追求更高更牛逼的目的了，现在呢？只是在目的中，如何与现实接轨了，这个是没有目的的，是没有追求的。以前是有目的的，是有追求的。现在是没有了。

以前是由追求，但是脑洞和思路会越飞越远。但是现在不飞了，而是直接如何向现实靠拢了。是的。以前是现实助我一臂之力，然后去规划出了更大的蓝图了。但是现在呢？则不是了，想法被限制了。是的。必须具备指导性的思想才能走的更远么？还是怎么的。现在确实是思想被限制住了。但是确实可以实现快速的实现了。是的。

快速实现，怎么说呢，没有激发出现实的力量了，甚至是，对于旧世界不友好。这个也不好。

那么之前呢？是通过旧世界的改造了，然后达到了新的目的了。对于旧世界的改造了。也就是说，我们无法选择旧世界了。所以才是唯物了。以人为本了。但是现在呢？我们站在了新世界的角度，任意的选择旧世界了。而以前呢，是一脉相乘的。即通过不断的改造旧世界，对于旧有的世界不断的改进了。通过发展旧世界，完全的贴近旧世界，完成了旧世界的升级了？是的。通过了旧世界的发展了，来实现了新的世界了。但是现在呢？条件的孵化作用，则是把自己给局限进旧世界了，所以想法反而是受限了。不遵守世界的发展规律了。遵守发展规律，就是通过发展旧世界，来达到新世界了。而不是新世界对于旧世界的自由选择了。是的。

但是新世界新思想对于旧世界的选择才是关键的。所以冯同学的脑洞是不够大的。但是足够的完成了新世界的实现工作了。

让旧世界的本质来决定？还是什么？还是新世界来决定了？是的？即关于旧世界的意志的崛起了？

那么新世界呢？以前的思路。自己写的关于爱的流动性的问题。那个时候是不同的。直接是新世界对于旧世界的改造了。而不是旧世界的发展了。关于新世界的跃升了？

唯物主义是没有界限的。但是唯心是圈子太小了。被局限在了当前的小圈子力了。因此思路没法去扩张了。思路的扩张了。？？但是可以快速的实现了。是的。

首先，如果要对于项目进行规划，必须要对于项目，进行整体的认识了。而抽象和概括，就是对于旧世界的整体认识了。然后是整体的发展了。

战略和规划，要求对于旧世界有整体的认识了。而不是反向的认识了。在整体的认识中，产生了战略的规划了。是的。

高屋建瓴的指导和规划，战略级的规划，已经没有了。操。但是没事，拿到了快速实现了。在小圈子内实现了快速的变现了？也是可以的。以前是思路的快速扩张，现在是思路的快速实现了。简直扯淡了。


===============================================================================================


重写level1.py,level2.py,level3.py等客户端函数。重新规划吧。

改造为面向对象。实在看着不舒服

生成新的task对象。包括response和参数了。

没有抽象和概括的能力，是无法进行规划的。是的。

所以ApiEvent 类，包括各种的资源。Task 类，参数和结果。 ApiEvent负责执行了。

增加httpExecute 函数。增加getHttpUrl 函数。是的。

关于数据库资源的频繁被使用。比如说API的调用。每次的调用都会涉及当前资源的释放和关闭了。不好。是的。如果每调用一次，就重新来一次，那就扯淡了。入非，可以在其上进行缓存了？谁调用函数，谁就是大爷了。谁就是主体了。是的。因此整体的资源，必须在flask框架中实现了。而不是在API内部了。此时或者每个对象来一次APIevent，是以用户为对象的？还是说来一次生成器？或者说迭代器了？所以，利用生成器，或者说是初始化全局变量。然后放进API中了？来处理了？

再加一层WSGI框架。缓存全局数据。url传递。 每个URL作为API，API即为其的URL了。是的。

写一个wsgi系统，加URL路由。是的。

首先是需要生成Requests和Response。是的。那就proxy代理吧。 或者说是LINK server.py 了。 account/server.py 可以添加requests和response。然后我们增加url路由系统了。带有app_factory 不太好啊。是的。

是wsigref简单？还是拆django？

拆django 1.8 尽量精简。是的。

flask werkzeug

web socket url 

拆django的url 路由功能，并添加到 swift account/server.py 中。先精简account/server.py 中

编写cloud/common包。把swift common 和daemon 拆出来。不采用url功能了。

对于swift进行拆分，对于不满意的地方，进行修改。把django的url移植进cloudserver。

不采用URL路径转发了。直接更具path而非method的方式研究了。调用函数。

cloud-common包。

cloud-server 包

现在对于api重写客户端了。进行客户端封装了。是的。 封装相关的参数。是的。

增加url路由，就好了。是的。

写一个url路由的分析。是的。

规则和需求？是的。

view.py和url.py 的路由。可以注册。

关于路由转发。不能快速的写，是因为对于所写的函数，形式不优美。不能达到自己的需求了。比如说传入路径。和返回函数。然后一个大列表，特别的难看了。对于不好的内容，如何换一种好看的方式？比如说大的列表，则拆成为各个的函数了。对于裸露的数据结构，则封装为类了。是的。比如说注册函数，可以用栈了。封装好内部的数据结构了，而不是直接简单的列表了。

为什么不接受程序的裸奔？而是要让程序好看点呢？是啊。奇怪了。

字符串查找，和遍历，for循环，太简单了吧。那么问题出现在哪里呢？

要求高了？不好看？所以要用别人的url了？其实自己写的也是可以用的？但是非的要搞成什么栈啊，字典之类的。扯淡啊。

莫非是看不起简单了？

现在就是编写API 的封装了。然后对于server端，重新调用相关的处理函数了。比如说封装的函数等。 或者调用数据库等。

指的就是自己无法接受自己所编写的简单的内容了。希望有高大上的呢，但是又不乐意了。是的。

先封装API，对于不太好确定的内容，先不写了。是的。

我们使用url和view的思想了。使用django的思想了。是的。

无法加载egg等库 ??但是wsgi程序可以。


# from swift.common.exceptions import LockTimeout, MessageTimeout
# import webob
def replace_dist(requirement):
    try:
        return pkg_resources.require(requirement)
    except pkg_resources.VersionConflict:
        e = sys.exc_info()[1]
        dist=e.args[0]
        req=e.args[1]
        if dist.key == req.key and not dist.location.endswith('.egg'):
            del pkg_resources.working_set.by_key[dist.key]
            return pkg_resources.require(requirement)

replace_dist("WebOb >= 1.0")

replace_dist("PasteDeploy >= 1.5.0")

通过捕获异常的方式，来获取错误信息了。是的。 而不是层层的函数返回错误了。受不了。

所以swift中的异常使用方式，是任意抛出，然后集中在某一层面上处理了？exception和raise的区别了？是的。

python 异常处理，错误处理.比较费劲，先不搞了。

精简 ev.sdata.db

api跑通后，会进行结果优化了。是的。 在相关的函数中增加值处理了Task类的格式化。是的。

当体设计完成后，开始核心模块了。是的。下一步就是用户系统，object系统等的设计了。是的。

设计核心的模块思路了。

重构swift。是的。让proxy 以及其之前的层层app，仅仅成为重新分发app的位置。且，req，携带分解前的req的信息。是的。明白，用户级别的操作。大致就是如此了。

以及整合proxy server下的各种规划了。是的。 比如说account_info 等等，我看完全，是没有必要的。是，让后端的account，container，obj重新进行操作了。是的。把所有和数据库相关，用户操作，通通交给account来处理。是的。

让proxy，成为重新分发req，而已了。是的。这个就是cloudfs的重写方向了。

并根据层层的解析后，重新生成新的request了。等于是把资源url，转化为功能url，让后端的server，container，object，account处理功能性的url等。是的。否则的话，整个的架构太乱了。日。

在此基础上，如何实现我们新的功能了？是的。比如说种种的数据库操作等等。是的。以及操作记录等等。是的。那就在功能url中来处理吧。是的。功能url中会作为资源url的分解了。

三层的url处理。先把资源url经过 proxy等一系列的前端，转化为了用户级别的url，然后记录用户操作，此会作为中间层了。以及统计层了？是的。

采用旧式API转化为新式API了。是的。

剥离相关的操作，比如说对于文件系统的操作，而转化为对于account等功能的处理。做到proxy不直接修改account文件系统了。是的。

且是防火墙功能了。

但是后期的api呢？旧式资源API，和新式API，会不会重新经过proxy呢？如果经过，有没有绿色通道呢？

关键，在此新的模型上，验证我们cloudweb的所有的后续功能了。

首先呢，就是先修改后端了？差不多吧。是的。

先修改文件下载？上传了？应该是了。是的。

代价太大了。那就小而烦的处理吧。不太喜欢做这种事情了，处理太多的小事，打tm的太多的补丁了。

如果之前架构搞的好，后续就不需要打补丁了。是的。所以架构问题，要么自己写。要么别人写了。

老老实实打补丁吧。是的。

打补丁导致的扩展性太差了。

关于实际存在概念上的逻辑，而不是抽象出来的逻辑了。如何进行的

关于用户操作记录，文件操作记录，不利用旧有的系统。而是新开一个。重新写入了，旧有的系统可以继续利用。但是今后会进行重新的导向了。

以及，就有的cloudfs的内容，是否需要重新的规划？比如说针对sqlite3的数据库的处理，是否需要放入到account中进行处理了？req来处理。

另外需要进行改革的，是其的ring系统，nodes查找系统，这个是最该被修改的了。修改后，ring系统就会被精简了很多了。是的。
然后整个的proxy才能实现精简的处理了。

主要忌殚是，如果修改的话 ，怕后期的测试支撑不了了。

一直在解决问题，而忽视了底层的驱动逻辑。底层驱动逻辑，比解决问题更加重要

打补丁吧，因为测试资源不够。日啊。

现在来看呢，操作记录就简单点吧，跟随数据库操作。跟随文件系统的修改了。是的。 否则的话，不能正确反应出来了。是的。

关于user和stobj的相关操作。日啊

那么资源防火墙呢？应该也是在后端了。是的。

前端不要去干涉了，把所有的操作统统放进后端吧。没有经历来处理前端，前端太tm的乱了。还是全部的放进后端吧。是的。

那么资源防火墙，和操作记录，应该就是搞定了，是的。

因此，编写的是后端插件，而不是前端插件了。妈的，前端没法写啊。是啊。

只对account和object和link进行限制了。不对container和dir进行限制了。

快点把项目写完，写完后，搞开源去了。用新的方法了。是的。知道多点还是好的。是的。 先写后端的插件，然后完成传值的优化了，错误检测等等。

如果有时间，就重写cloudfs了。是的。 重写cloudfs。利用更好的扩展。

资源防火墙搞定，限制account和object

下一步，就是quota了。直接采用一层的req，mission，直接调用events的函数了。而不走daemon了。然后在daemon处进行修改了。是的。数据库呢？还是需要的。

结果会被details进行收集，然后在views.py 中进行统一的判断。是的。无乱是关于错误信息，还是说数据需要进行重新格式化了。details.py 只是简单的对于cloudfs的api进行封装了。

关于用户模块的处理。是的。 用户浏览功能了。是的。

在用户注册时？没有email和其他的辅助信息啊。用户注册？和用户使用email和passwd获取token。因为是已经注册了。是的。现在是注册到fs上。但是呢，数据库呢？如何处理？而数据库，其实呢是根据fs来的。所以需要注册到数据库了。

此处涉及到用户系统的重新定位了。 和一般的流程是不同的。是的。 增加用户注册操作。是的。 在进行userinit的过程中，获取到用户的所有信息了？存储在metadata中的信息了？

在把cloudfs重新合入到vs中的时候，需要重新架构了。是的。重构了。但是这个活不做，去写redis了。写一个集群系统。就当自己的思路了。是的。

不过确实是有点难。啊。

思想想的远，那是还没有变现，一旦变现后，就是坑变成了金山了。立刻从山下到山上了。是的。

代码，组织架构管理。是的。

数据库操作被分成了两大块，一块是cloudfs的插件一块是cloudweb中events的获取结果了。

对于数据库操作的几点处理

一层最基础的conn处理。

二层，对于stobj，对于user的基础处理 增删改查。

三层。对于stobj上各种复杂处理。根据业务的叠加，等等。是的。

因此数据库的优化，和处理。在处理业务表的时候。

因此代码的组织规划和管理，就是随着表的横向增加，在这个过程中，需要有新的内容增加，而原有的简单设计，无法容纳了。此时就是需要进行重构了。是的。

因此，我们是需要一个工作日，把数据库给处理好的。而所谓的分化和处理，就是在写代码的过程中，新的内容出现了，过去的容纳不了了。因此，面向过程的核心，向面对对象的转化，就是因为是一代单传的局面被打破了。此时导致了分层思想的出现了。每层思想，都会有相应的多个对象的出现了。是的。

数据快这块，还是需要重构的。原来的架构太差劲了。是的。所以说，不要一直局限在一个地方写，写会这个，再去写会那个了。是的。就很好了。是的。然后这个过程中，当初不能容忍的内容，被重构了。是的。新的思想，就形成了。而小程序，是做不到这种的设计思想的。是的。

做的经验越多，那么提升的经验也越多了。思想是太宽容了，但是现实不能宽容。所以要扯淡了。是的。

写会就是需要重构了。所以获取到重构的思想，那就去写新的项目。并把新的项目做大。所以不能局限于一个项目了，一个项目的增长是不好的。是的。把炼手的程序都写写，都进行变现了。

写出的代码，要像艺术品一样了。是的。所以说多个的项目都是需要我们来写的。是的。python中炼手的项目。不管了，变现是很重要的。是的。那么就是大数据中，和docker中的变现了？

写完这些后，再去搞新的项目了，如何？所以说单打一面的机会是非常的重要，在这个过程中，遇到的问题，需要自己去重新搞，这个是非常掉的。

所以一开时就是简单的面向过程了，但是需要经验丰富后才能搞出来面向对象了。是的。

写ui确实没有意思。要写就写后台，是的。

程序炼手，很重要啊。

重构的时候，不影响原来的内容，然后重新写一个吧。还是。是的。

改别人的源码，进步不大。而是自己单打独斗中，自己设计一个程序，这个过程中的属性成长，和代码设计思路，那是完全的不一杨了。所以，不改，不进行微创新。即使写，也是要自己重写一遍的。

所以需要我们从零开始，重新写一个。而不是去改别人的源码，那个是没有多大的意义的。要培养单打独斗的能力。而不是利用别人的设计了。是的。

这个过程中的项目分析，设计和思考是非常的重要的。

把select和update，delete的相关的内容被抽象出来了。是的。

传教connection，积极，conn的基础操作。增删改查，搞出来。是的。

先把所有的mysql函数实现了，然后再进行分发了。

用户级别的user的增删改查。

在swift层，增加一层数据库操作。有db.prev,db.post,db.run 等操作。 新的对象了。是的。

## create table record( id bigint NOT NULL PRIMARY KEY AUTO_INCREMENT,msg text NOT NULL,time datetime,uid bigint NOT NULL,oid bigint NOT NULL,CONSTRAINT xiaodi_ibfk_1 FOREIGN KEY (uid) REFERENCES user (id) on delete cascade on update cascade  ); ## error

create table record( id bigint NOT NULL PRIMARY KEY AUTO_INCREMENT,msg text NOT NULL,time datetime,uid bigint NOT NULL,oid bigint NOT NULL);

alter table record add constraint stobj_check foreign key(oid) references stobj(id) on delete cascade on update cascade;

alter table record add constraint user_check foreign key(uid) references user(id) on delete cascade on update cascade;

user表的id 类型为int，不是bigint

create table user(id bigint NOT NULL PRIMARY KEY AUTO_INCREMENT,name varchar(255) NOT NULL,type int ,email varchar(255) NOT NULL,password text,state char(8));

## alter table user modify column id bigint; 修改无用，需要删掉表重新创建。

insert into record (msg,time,uid,oid) values('ok','2015-12-12 1:1:1',1,1311);

>>> import datetime
>>> str(datetime.datetime.now())
'2016-03-04 14:26:49.869871'

完善 fs,object,quota,record,search,user 等系统。

剩余host ，config了。

python request的文件下载功能？文件读写可以理解了。读取http协议。但是文件下载呢？

cloud-server，如何完成，上传文件，和下载文件中转站的问题了。因为在events中所执行的内容，还是说是本地的路径了。

但是在cloud-server中，是不能有本地路径的。所以，就是需要先接受数据了。然后分发数据了。

文件上传，经过cloud-server中转，首先发送用户名，然后获取到token，会被作为header，发送给cloud-server了。然后带上了数据了。 直接就header吧。反正也是看path的。

研究httplib的源码，关于body的上传问题。

req.body，目前cloud-server 作为中转站的问题。还是作为本地文件路径的方式。现在就是要进行去路径的方式了。

去路径，就是也是需要file(path)的，现在，如何把req.body 转化为file(path),作为文件描述符来使用。req.body 不可直接进行使用了。是的。

req.environ['wsgi.input'].read ??是这个么？

因此req.body 带有read函数即可了。是么？因为httpconnection 中既有read函数。需要body的read了。

            blocksize=8192
            if hasattr(str,'read') and not isinstance(str, array):
                if self.debuglevel > 0: print "sendIng a read()able"
                data=str.read(blocksize)
                while data:
                    self.sock.sendall(data)
                    data=str.read(blocksize)
            else:
                self.sock.sendall(str)

所以如何为字符串"aa" 增加read函数？

req.body 是字符串类型的。没有read函数，所以不能内存中使用了。但是我们要在内存中，尤其是转发的过程中，杜绝使用字符串。要使用文件描述符。因此，现在的任务是，如何把字符串类型，转化为带有read函数的文件描述符？所以，对于cloudfs函数接口，进行重新的定义。是的。把路径，转为文件描述符了。是的。

如何生成，env['wsgi.input']的生成过程。不要直接使用req.body不好。是的。req.body是字符串。

我们的作用也是生成这个了。所以，写req，和写resp，在网络中传输数据，如何把传输的数据转变为文件描述符来转变了。

req.environ['wsgi.input'].read() 读完后req.body为空 ，但是req.body可以重复的读了。是的。 req.body 和req.environ['wsgi.input'] 的内在机制？尤其是字符转化为文件描述符的机制。即，传递文件描述符了。这个应该是不占用内存吧。

修改cloudfs的相关路径，把涉及到的路径，升级为文件描述符了。是的。

传递文件描述符，还是需要同样传递长度了。 content-length

上传文件，完成了中转，那么下载文件呢？还是要传递wsgi.input 。把其转化为wsgi.input了。是的。

下载文件的时候，会返回resp，以及resp.read(),说明也是文件描述符。那我们该如何生成新的response并返回？

完成文件上传和下载，然后并完成object的其他的函数了。

如何对于获取到的数据，转化为文件描述符的？HTTPresponse。产生resp.read()

self.fp = sock.makefile('rb', 0) -> s = self.fp.read(amt)

等于是必须往sock中写数据才可以了。因此，恢复数据的时候，就是读一遍，然后写了。

_make_app_iter_reader，app_iter, _make_app_iter

_make_app_iter_reader,_make_app_iter 生成器。

_make_app_iter - >resp.app_iter
生成器在文件读写中的作用如何？

Response __call__ 函数，返回生成器。 _response_iter，无作为，或利用body 生成新的_app_iter 

python HttpProtocol

返回生成器，是为了让header先写。然后在写需要的数据了。是的。这个就是response的作用了。

在http中，所有的body数据，都是需要header发送完后才发送。所以，当前，需要对于接受到的数据，生成一个app_iter .

以及把md5改造为app_iter

如何写一个app_iter ?

swift中采用了队列。没有文件的关闭和打开。

那么在obj/server.py中呢？

以生成器的方式，去写文件了。是的。

写一个文件类，生成器？还是迭代器？其的对象传递给response了。是的。那么对于内存中的数据，如何处理？比如说接受到的数据？因此，即可以从socket中读取，也是可以从文件读取了。

是的。迭代器，和生成器。

resp自己本身是迭代器么？迭代数据？和生成器？

返回的httpserver 端的resp应该是，但是接受到httpclient 端 的resp不是。

source,为possible_source 为httpclient端的 source。 _make_app_iter 即为讲解了如何把client端的resp，封装为iter 迭代器生成器了。
在_make_app_iter 中开了两个协程，一个为了读，一个写，并使用了队列。这个应该主要是为了缓冲了。缓冲数据了，防止两端的通信网络都不好了。是的。

在下载数据时，进行数据中转时，只要玩命的读，然后放进读列就好了。是的。但是现在不能读。是的。

把网络数据封装为迭代器，不容易啊。

读写完内存数据后，比如说client端的response，需要进行一个关闭。是的。

对于resp封装为一个source就好了。然后使用迭代生成器，但是没有类了？

但是当前的mission的data返回，有个弊端，直接就关闭了。不问结果如何了。

对于文件下载的mission，还是需要一个迭代器的。是的。

会return一个迭代器了。而不是直接的就是完整的数据了。是的。

为文件下载写新的mission执行类。返回新的task类。

先对于结果进行封装。

返回的客户端 resp.read()  能否作为iter ？不能。因为是一直往前走的。

刚才实现的是类对象迭代器，即有__iter__函数。现在增加一个函数迭代器？即有yield 函数？

客户端的resp不是类迭代器。read函数不是类迭代器。

增加yield 的类，或者对象，其的本身即为迭代器了。是的。

所以，该函数即为迭代器了。是的。 因此api本身即为迭代器了。

直接返回生成器，不准备采用队列进行缓冲了。

obj/server.py 中 GET 函数。 request.get_response(Respoinse(app_iter=File,request=req)) ??  返回的就是request，可以
直接返回response了。试试看。

关于req的headers拷贝的问题。在uploadfile函数中的，要不实在是难看。

如何实现client端的resp和req的克隆？

db操作，需要拆开，先。是的。 拆分为middleware，和访问的db形式了。

主要是因为访问的路径是不同的。 访问的内容是不同的了。一般不怎么访问数据库。是的。

==============================================================================================
增加数据库操作层，搜集用户操作的action和用户操作的结果，response。一旦操作成功，那就在此数据库层中进行修改了。

增加全局变量，对于数据库的检测了？ 使用新的线程？ 检测文件是否存在？判断数据库是否连通了？是的。

包括拦截用户request和response，进行参数拆分和分析了。构建平台，和条件。

把其作为平台，继续向上层发展了。比如说，文件系统搞好之后，那就可以开始为上层提供API了。所有的API操作应该重定向数据库？还是重定向到文件系统呢？继续文件检索，和文件等操作。文件相关关系等操作。

多和数据库打交道。比如说文件搜索。而不用和文件系统系统。把大量的IO操作，搬到数据库中来。是的。而不是所有的操作都搬到数据库中来。目前metadata，还是由文件系统来做吧。目前只是把数据换了一个形式了。是的。

可以换一种思考，即我们现在有数据了。有关于用户，和文件的数据了。而他们将会以统一的方式进行访问了。是的。

当前所有的API，都是可以直接和文件系统打交道的。是的。

## 文件系统和数据库一致性校验。用户级别的。

## 文件检索。初级检索，和复杂检索。初级检索中不直接现实文件的全路径。只有满足用户的需要后，才会进一步的访问数据库了。现在提供API的条件是否成熟了么？

## 文件检索的基本思路。全局，则全局搜索。用户，则先获取单个用户的所有数据，然后进行搜索了，用户数据量少。而不用添加account字段了，会使已有的API不好看，比较乱
## 制作rpm包？

面向层次的编码。面向quota，面向用户。面向文件等等。get_object_network_url.面向metadata等等。 

在metadata上，还是使用传统的curl参数的方式吧。编写request，和response层。等。以及，在web框架中，需要从原始的字节流生成request和response等。

python网络编程模块。 requests,httplib,httplib2 ,urllib,urllib2 python-httplib2.noarch,python-rest-client

用httplib把curl命令重新写一遍，requets和response。例如pycurl？？ pycurl 也很方便。 这样可以直接对于错误进行分析了，而不是通过肉眼来观察了。

python网络编程了。是的。 编写管道？？

目标要明确，不要一直晃悠。

给cloudfs增加插件源码,并测试。 直接添加到site-packages中。

yum install libaio-devel dos2unix python-netifaces python-webob1.0 python-paste-deploy1.5 python-eventlet python-sphinx10 pyxattr

增加对于文件系统修改的测试了？

增加quota表？和metadata表？

外键后续进行考虑

买本mysql的书看看 mysql技术内幕？

增加webconf 表 存储系统设置

密码加密传输，传输密文

metadata 的处理？如何进行？

一旦metadata修改后，会被从缓存中清掉。不会修改三次的。

决定最小力度的影响cloudfs。

如果对于整体的cloudfs的整体不满意，才会进行整体的设计了。但是目前来看，是看不到整体了。只能看到局部了。是的。

关于大力度，是建立小力度之上的。是的。

数据库一坏，那么整个的cloud云服务就不能用了。但是可以正常访问文件系统了？给文件系统中用户的操作留记号？表示会重新构建此>用户的数据库文件系统了？

应该要暂停，并把sql语句写到文本中保留了。如果数据库不能用。是的。修改好数据库后，在重新执行sql语句。

from urllib import unquote
unquote(req.path) /zhu__feng00000com/0/AUTH_zhu__feng00000com/%E6%B5%8B%20%E8%AF%95

## 在一个事务中，只有一个conn数据库连接。搞成面向对象的方式

## 根据container的情况，还是需要重新写一遍的测试用例的。重新组织一遍。

## 全局数据库连接对象编写？是的。

## 全局mysql连接对象？是的。

## 设计思路，关于资源的释放，不以函数调用为主了。以对象为主。不是操作主导资源。而不是资源对象主导操作了。因为资源的分配太过于宝贵了。函数可以多多的调用。但是数据库资源的分配不能了。

## 手动控制数据库的释放。close函数。
#
## 面向资源编程，那就是说和资源相关的调用函数，都是在资源类中了？

## 写数据到mongodb ,pymongo 看官方文档。是比较好的。

## aggregation framework ,实现max函数。 mongodb之外处理，聚合太难用了，或者二分搜索。还是很快的。

## collection.find_one({"myfield": {"$exists": True}}, sort=[("myfield", 1)])["myfield"]

## python yeild iter next 等

## 增加pthon 锁的访问


## 用户模型的设计。 以及使用网络的方式，在cloudfs，增加统计API，增加到数据库，是的。包括访问文件等等，是的。

## 设计API，不增加其他的内容。

## 用户模型，和统计视图的访问是的。 用户模型的设计？该如何搞？

## 用户信息采集，用户信息注册？用户登录？单用户管理，用户信息录入，用户行为统计，是的。 依赖于注册API，cloudfs发送用户操作信息，给系统。

## 往业务中填充零件，填充技术零件，促进编程了，是的。买书。

## 编程，把书上的零件，编一遍。提供平台。不止是简单的算法。包括各方面的技术了？比较热门的技术？比如说WEB

## 需要往源码，填充其他的零件等等。这个就是技术驱动了？是的。

## 当前是一个个的处理，后期改为缓存队列从数据库中取缓存队列了。
 
## 设计 mongodb的model,编写mongodb，做到业务和技术脱离。

## mongo中的db读取。数据库建立，表的建立，表的写入，表的读取，表的修改，表的查询，需要写这些接口了。把藏在业务的函数，给独立出来，是比较好的。

## poll可以接受数据，但是没法处理，否则影响接受的速度。所以，要求放到对列中，队列头进行处理，处理行。会有一个缓存专门来处理。python的queue和C语言的内存分配。

## 从mesages一次性的读取1000行，然后放入链表中，然后从链表中读取，一次次的读取行。如何？或者存入到mongodb中，这样就可以防止进程挂掉了。是的。 

## 需要对链表和表进行加锁，但是数据库就不用。

## 需要重视效率，所以还是python，c语言太慢了，采用数据库的方式。增加数据块序号，和处理标志，此块数据已被处理。

## 把业务和技术分开，比如此次的数据快的处理，就是业务和技术揉和在了一起了，所以要把技术分开，独立一个平台，然后在此平台上承载业务了。

## 因此，要谈技术，就谈技术，谈业务，谈业务了。

C语言文件读取，每个数据块是由编号的。

制作软件包，安装配置文件，安装后执行脚本。

## mongodb业务信息表

## mongodb接口

性能数据，暂时不理

安装anaconda 以及系统等 ，重写进行开发。

产生独立程序，比如说正则表达式。涉及的知识，不是说其满足了当前的需求就可以了，还要让其可以独立成文，才是好的。

后端会被作为独立信息发送到数据库中，但是会被统一的提取出来，作为当前的消息，发给前端，统一显示。

写程序不能搞大锅菜，一锅端，所有的功能都揉和在一起，不行。比如独立，分开，不能融合在一个程序里面，不能被整体的功能所绑架
了，要独立分开才行了，是的。所以，功能要独立，比如写网络发送，mongodb操作，或者网络分发的框架等等。是的。必须要分开，拆>开的写，坚决不能为了一个完整的功能而写道一起，那样什么都写不了。

写独立功能的函数。

网络请求的收发。

网络客户端和服务端。

mongdb的客户端分发操作


研究开源包拆分开源的知识，以后，就是偏网络框架了，是的。

把开源的内容给拆分出来，基本上就是学习了一遍了？但是估计不好拆分，哈哈。

tornado,anaconda，django，psutil，swift，keystone，memcached，mongodb。调用其他的程序接口？是的。

来吧什么牛逼写什么。重复造轮子，可以是有大用。是的。不要脱离现实，是的。人啊，就是需要机会，需要平台，在这个平台或者机会中，人就得到训练了。是的。升级的好机会。

编写后端开发过程，和技术框架对于各模块的支撑。是的。

metadata 的处理？如何进行？

一旦metadata修改后，会被从缓存中清掉。不会修改三次的。

决定最小力度的影响cloudfs。

如果对于整体的cloudfs的整体不满意，才会进行整体的设计了。但是目前来看，是看不到整体了。只能看到局部了。是的。

关于大力度，是建立小力度之上的。是的。

数据库一坏，那么整个的cloud云服务就不能用了。但是可以正常访问文件系统了？给文件系统中用户的操作留记号？表示会重新构建此用户的数据库文件系统了？

应该要暂停，并把sql语句写到文本中保留了。如果数据库不能用。是的。修改好数据库后，在重新执行sql语句。

from urllib import unquote
unquote(req.path) /zhu__feng00000com/0/AUTH_zhu__feng00000com/%E6%B5%8B%20%E8%AF%95

在一个事务中，只有一个conn数据库连接。搞成面向对象的方式

根据container的情况，还是需要重新写一遍的测试用例的。重新组织一遍。

## select UNIX_TIMESTAMP(NOW())-UNIX_TIMESTAMP(time) from record ;

## 完成所有的接口调用，如果是从restful接口，则复用其的status和msg等。

## 为record增加时间。是的。可以进行重复插入了。

## 增加用户返回类型。增加数据库反问。

开始完全的进入第二阶段的开发了。是的。进入第二第三阶段的开发。

修改token的超时。 假数据。

新建cloud-lib包，分开，api和daemon分开了。是的。

并方便我们去构建其他的包了。是的。

cloudlib，会整合进去cloudfs的包了。是的。

今后新的开发工作会迁移到lib上，而针对于cloudweb的开发，将会被废弃了。是的。

安装新的包，并且新的功能，会增加到新的lib上了。可同时使用lib或者cloudweb了。是的。方便服务的调用，而不用频繁的调用接口了。是的。

让lib上的api可以跑通了。是的。

rpmbuild 时，关于lib包的失败，lib/cloudlib/中没有__init__.py 文件。

RPM build errors:
    File not found: /root/rpmbuild/BUILDROOT/cloud-1.1-15.el6.x86_64/usr/lib/python2.6/site-packages/cloudlib

增加tree接口。数据库？还是restful方式？

增加管理员数据了。是的。不涉及真正的用户创建了。administrator

准备把源码整合起来，比如说web，common，lib，server等。是的。都放在一个里面。就像之前的swift的源码一样了。是的。一个源码，多个包。是的。

dmidecode.获取硬件信息，主板，内存，cpu，网卡等信息。

smartctl -a /dev/sda

mii-tool

dmidecode |grep -A16 "Memory Device$"
Memory Device
	Array Handle: 0x002D
	Error Information Handle: Not Provided
	Total Width: 64 bits
	Data Width: 64 bits
	Size: 4096 MB
	Form Factor: DIMM
	Set: None
	Locator: DIMM_A1
	Bank Locator: A1_BANK0
	Type: DDR3
	Type Detail: Synchronous
	Speed: 1333 MHz
	Manufacturer: Kingston        
	Serial Number: D12F123C  
	Asset Tag: A1_AssetTagNum1
	Part Number: 99P5471-011.A00LF 

获取system 信息？
dmidecode |grep -A16 "System Information$"

mii-tool lspci 

fdisk 

psutil

grep -A NUM, --after-context=NUM

获取主板信息
dmidecode |grep -A18 "Base Board Information$"
Base Board Information
	Manufacturer: ASUSTeK Computer INC.
	Product Name: F1A75-M
	Version: Rev X.0x
	Serial Number: MF70B7G01200921
	Asset Tag: To be filled by O.E.M.
	Features:
		Board is a hosting board
		Board is replaceable
	Location In Chassis: To be filled by O.E.M.
	Chassis Handle: 0x0003
	Type: Motherboard
	Contained Object Handles: 0

lshw -c cpu -json
    "id" : "cpu:0",
    "class" : "processor",
    "claimed" : true,
    "handle" : "DMI:003D",
    "description" : "CPU",
    "product" : "AMD A6-3650 APU with Radeon(tm) HD Graphics",
    "vendor" : "Advanced Micro Devices [AMD]",
    "physid" : "2",
    "businfo" : "cpu@0",
    "version" : "AMD A6-3650 APU with Radeon(tm) HD Graphics",
    "slot" : "FM1",
    "units" : "Hz",
    "size" : 2600000000,
    "capacity" : 2600000000,
    "width" : 64,
    "clock" : 100000000,
    "configuration" : {
      "cores" : "4",
      "enabledcores" : "4",
      "threads" : "4"
    },

lshw -c network -json
                                                                                                    {
    "id" : "network",
    "class" : "network",
    "claimed" : true,
    "handle" : "PCI:0000:03:00.0",
    "description" : "Ethernet interface",
    "product" : "AR8151 v2.0 Gigabit Ethernet",
    "vendor" : "Atheros Communications Inc.",
    "physid" : "0",
    "businfo" : "pci@0000:03:00.0",
    "logicalname" : "eth0",
    "version" : "c0",
    "serial" : "f4:6d:04:7c:f4:75",
    "units" : "bit/s",
    "size" : 100000000,
    "capacity" : 1000000000,
    "width" : 64,
    "clock" : 33000000,
    "configuration" : {
      "autonegotiation" : "on",
      "broadcast" : "yes",
      "driver" : "atl1c",
      "driverversion" : "1.0.1.0-NAPI",
      "duplex" : "full",
      "ip" : "192.168.36.1",
      "latency" : "0",
      "link" : "yes",
      "multicast" : "yes",
      "port" : "twisted pair",
      "speed" : "100Mbit/s"
    },

ip addr show dev eth0

2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP qlen 1000
    link/ether f4:6d:04:7c:f4:75 brd ff:ff:ff:ff:ff:ff
    inet 192.168.36.1/16 brd 192.168.255.255 scope global eth0
    inet6 fe80::f66d:4ff:fe7c:f475/64 scope link 
       valid_lft forever preferred_lft forever

lshw -c disk -json
                                                                                                                                                                                                                                                                      {
    "id" : "disk",
    "class" : "disk",
    "claimed" : true,
    "handle" : "SCSI:04:00:00:00",
    "description" : "ATA Disk",
    "product" : "WDC WD10EZEX-00R",
    "vendor" : "Western Digital",
    "physid" : "0.0.0",
    "businfo" : "scsi@4:0.0.0",
    "logicalname" : "/dev/sda",
    "dev" : "8:0",
    "version" : "80.0",
    "serial" : "WD-WMC1S2415594",
    "units" : "bytes",
    "size" : 1000204886016,
    "configuration" : {
      "ansiversion" : "5",
      "logicalsectorsize" : "512",
      "sectorsize" : "4096",
      "signature" : "000063c7"
    },
    "capabilities" : {
      "partitioned" : "Partitioned disk",
      "partitioned:dos" : "MS-DOS partition table"
    },
    "children" : [
                                  
    ]
目前不考虑disk label，是的。

Manufacturer: Kingston
        Serial Number: D12F123C
        Asset Tag: A1_AssetTagNum1
        Part Number: 99P5471-011.A00LF

create table host(id bigint NOT NULL PRIMARY KEY AUTO_INCREMENT,name varchar(255),uuid varchar(255),product varchar(255),manufacturer varchar(255),version varchar(32),serial varchar(64) NOT NULL,asset_tag varchar(255),available varchar(8));

create table host_mem(id bigint NOT NULL PRIMARY KEY AUTO_INCREMENT,host_id bigint NOT NULL,total_width varchar(16),data_width varchar(16),size varchar(16),form_factor varchar(64),speed varchar(16),manufacturer varchar(255),serial varchar(64) NOT NULL,asset_tag varchar(255),part_number varchar(255));

create table host_net(id bigint NOT NULL PRIMARY KEY AUTO_INCREMENT,host_id bigint NOT NULL,logicalname varchar(32),description varchar(255),product varchar(255),vendor varchar(255),physical_id int,bus_info varchar(255),version varchar(32),serial varchar(64) NOT NULL,size bigint,capacity bigint,width bigint,clock bigint,mtu int ,mac varchar(266),inet varchar(64),is_primary varchar(8));

create table host_cpu(id bigint NOT NULL PRIMARY KEY AUTO_INCREMENT,host_id bigint NOT NULL,description varchar(255),product varchar(255),vendor varchar(255),physical_id int,bus_info varchar(255),version varchar(32),size bigint,capacity bigint,width bigint,clock bigint,cores int,enabledcores int,threads int);

create table host_disk(id bigint NOT NULL PRIMARY KEY AUTO_INCREMENT,host_id bigint NOT NULL,logicalname varchar(32),description varchar(255),product varchar(255),vendor varchar(255),physical_id int,bus_info varchar(255),version varchar(32),serial varchar(64) NOT NULL,size bigint);

alter table host_mem add constraint mem_check foreign key(host_id) references host(id) on delete cascade on update cascade;
alter table host_net add constraint net_check foreign key(host_id) references host(id) on delete cascade on update cascade;
alter table host_cpu add constraint cpu_check foreign key(host_id) references host(id) on delete cascade on update cascade;
alter table host_disk add constraint disk_check foreign key(host_id) references host(id) on delete cascade on update cascade;

host表： id 数据库id，name 主机名，uuid 主机唯一标志符，product 产品名，manufacturer生产商，version 版本，serial 序列号  available 主机是否可用
host_mem表：id数据库id，host_id 主机id，total_width 位宽,size 容量，speed 主频，manufacturer 生产商，serial 序列号
host_net 表： id数据库id，host_id 主机id，logicalname 设备名，description 描述，product 产品名,vendor 生产商，bus_info 总线信息，version 版本号，serial 序列号，size 容量，width 位宽,clock 频率，mtu，mac mac地址，inet ip地址，is_primary是否>为通信ip
host_cpu 表: id数据库id，host_id 主机id，description 描述，product 产品名,vendor 生产商，bus_info 总线信息，version 版本号， size,capacity,width,clock,core,enablecores,threads
host_disk 表：id数据库id，host_id 主机id，logicalname 设备名，description 描述，product 产品名,vendor 生产商，bus_info 总线信息，version 版>本号，serial 序列号，size硬盘容量

create table stat_cpu(id bigint NOT NULL PRIMARY KEY AUTO_INCREMENT,host_id bigint NOT NULL,timestamp timestamp,utilization float(8,4));

create table stat_mem(id bigint NOT NULL PRIMARY KEY AUTO_INCREMENT,host_id bigint NOT NULL,timestamp timestamp,total bigint,available bigint);

create table stat_net(id bigint NOT NULL PRIMARY KEY AUTO_INCREMENT,host_id bigint NOT NULL,timestamp timestamp,bytes_sent_per_sec bigint,bytes_recv_per_sec bigint,packet_send_per_sec bigint ,packet_recv_per_sec bigint);

create table stat_disk(id bigint NOT NULL PRIMARY KEY AUTO_INCREMENT,host_id bigint NOT NULL,timestamp timestamp,disk_read_per_sec bigint,disk_write_per_sec bigint);

create table stat_storage(id bigint NOT NULL PRIMARY KEY AUTO_INCREMENT,host_id bigint NOT NULL,timestamp timestamp,uuid varchar(255),path varchar(255),total bigint,used bigint,free bigint,available varchar(8));


alter table stat_cpu add constraint stat_cpu_check foreign key(host_id) references host(id) on delete cascade on update cascade;
alter table stat_mem add constraint stat_mem_check foreign key(host_id) references host(id) on delete cascade on update cascade;
alter table stat_net add constraint stat_net_check foreign key(host_id) references host(id) on delete cascade on update cascade;
alter table stat_disk add constraint stat_disk_check foreign key(host_id) references host(id) on delete cascade on update cascade;
alter table stat_storage add constraint stat_storage_check foreign key(host_id) references host(id) on delete cascade on update cascade;

stat_cpu表：id数据库id，host_id 主机id，timestamp时间戳，utilization 使用率
stat_mem表：id数据库id，host_id 主机id，timestamp时间戳，total总量，available 剩余量
stat_net 表：id数据库id，host_id 主机id，timestamp时间戳，bytes_sent_per_sec 每秒发送字节，bytes_recv_per_sec 每秒接收字节，packet_send_per_sec 每秒发送数据包，packet_recv_per_sec 每秒接收数据包
stat_disk 表：id数据库id，host_id 主机id，timestamp时间戳，disk_read_per_sec 主机每秒读字节，disk_write_per_sec 主机每秒写字节
stat_storage 表：id数据库id，host_id 主机id，timestamp时间戳， uuid存储唯一标志符，path存储挂载路径，total 存储总量，used 已使用量，free剩余量,available 存储是否可用

直接使用stat_disk 统计进程的io，使用proccess的统计。进程监控来实现了。是的。# 不仅反映了fs，disk以及process的io了。

因此，在io统计上，完全的由本进程来接手了。而不是交给系统命令来处理了。是的。

host,host_mem,host_net,host_disk 会以序列号作为其的唯一标志符了。如果没有，则会默认生成了。是的。host_cpu 则不用过分的详细了。是的无序列号。

## create table stat_proc_io(id bigint NOT NULL PRIMARY KEY AUTO_INCREMENT,host_id bigint NOT NULL,timestamp timestamp,disk_read_per_sec bigint,disk_write_per_sec bigint);

mysqldump -u root -p111111 cloudweb > dbcloudweb.20160401.bak

研究下软件外包，好像不难，还能挣钱，不错。是的。

学习下手机app，开始搞外包。好像很爽。有时间啊。就去挣钱去。是的。

http://www.epwk.com/zt/login/

http://www.kuai.ma/request.html

好像可以挣钱，还能锻炼项目的设计能力。当然了，有项目设计能力，就是要去做高大上的项目了。是的。

增加高大上项目。

比如对于当前的系统，增加智能调度系统。是的。根据cpu，mem，和request个数等。是的。

吹把。以及告警和邮件服务等。

一是要设计，但是还是要高大上。是的。

反馈系统。这个是非常的关键的。是的。

关于项目的web的开发，新开一个分支，支持新的monitor了。是的。也是在家处理了。是的。git上的不同的分支处理，在svn上是如何处理的？奇怪啊。是的。

一次只更新一回host，是的。

ss[-1000:]

create table stat_cpu(id bigint NOT NULL PRIMARY KEY AUTO_INCREMENT,host_id bigint NOT NULL,timestamp timestamp,utilization float(8,4),seq bigint);

create table stat_mem(id bigint NOT NULL PRIMARY KEY AUTO_INCREMENT,host_id bigint NOT NULL,timestamp timestamp,total bigint,available bigint,seq bigint);

create table stat_net(id bigint NOT NULL PRIMARY KEY AUTO_INCREMENT,host_id bigint NOT NULL,timestamp timestamp,bytes_sent_per_sec bigint,bytes_recv_per_sec bigint,packet_send_per_sec bigint ,packet_recv_per_sec bigint,seq bigint);

create table stat_disk(id bigint NOT NULL PRIMARY KEY AUTO_INCREMENT,host_id bigint NOT NULL,timestamp timestamp,disk_read_per_sec bigint,disk_write_per_sec bigint,seq bigint);

create table stat_storage(id bigint NOT NULL PRIMARY KEY AUTO_INCREMENT,host_id bigint NOT NULL,timestamp timestamp,uuid varchar(255),path varchar(255),total bigint,used bigint,free bigint,available varchar(8),seq bigint);

alter table stat_cpu add constraint stat_cpu_check foreign key(host_id) references host(id) on delete cascade on update cascade;
alter table stat_mem add constraint stat_mem_check foreign key(host_id) references host(id) on delete cascade on update cascade;
alter table stat_net add constraint stat_net_check foreign key(host_id) references host(id) on delete cascade on update cascade;
alter table stat_disk add constraint stat_disk_check foreign key(host_id) references host(id) on delete cascade on update cascade;
alter table stat_storage add constraint stat_storage_check foreign key(host_id) references host(id) on delete cascade on update cascade;

基本上，每张表，每个主机，都对应着自己的seq了。是的。

需要我们先设计客户端。然后先写服务端，然后客户端在写的过程中，才有依靠了。是的。

关于架构组织。涉及到server，common，lib，和monitor等。

以及框架流程优化了。是的。解决一些bug了。是的。

增加枷锁的数据库处理了。是的。

创建线程，编写线程类。和初始化全局变量了。

加锁的全局变量。需要这个。

多台主机同时启动的时候，会出问题了。是的。

with getlock(conn) as mylock
需要这样的方式才行了。也是可以的。是的。

制作monitor rpm包，是的。

主机uuid初始化。

在服务启动的时候，会检测路径，如果uuid存在，则生成，如果不存在，则不能生成了。是的。

构建http 客户端了。是的。

